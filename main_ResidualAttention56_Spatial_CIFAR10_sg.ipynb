{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Attention-56 with Spatial Attention using CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, TensorBoard\n",
    "#from utils.preprocess import CIFAR_preprocess, add_noise\n",
    "from utils.AttentionResNet_CIFAR import AttentionResNet56_spatial\n",
    "from utils.residual_unit_CIFAR import residual_unit\n",
    "from utils.attention_block import spatial_attention_stage_1, spatial_attention_stage_2, spatial_attention_stage_3\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR-10 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (40000, 32, 32, 3)\n",
      "y_train shape: (40000,)\n",
      "x_validation shape: (10000, 32, 32, 3)\n",
      "y_validation shape: (10000,)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "## dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "train_num = int(len(x_train) * 0.8)\n",
    "x_val = x_train[train_num:, :, :, :]\n",
    "y_val = y_train[train_num:]\n",
    "y_val = y_val.reshape(-1)\n",
    "x_train = x_train[:train_num, :, :, :]\n",
    "y_train = y_train[:train_num]\n",
    "y_train = y_train.reshape(-1)\n",
    "\n",
    "y_test = y_test.reshape(-1)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_validation shape:', x_val.shape)\n",
    "print('y_validation shape:', y_val.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean for each channel\n",
    "mean = np.array(np.mean(x_train, axis=(0, 1, 2))).reshape([1,1,1,3])\n",
    "x_train = x_train-mean\n",
    "x_val = x_val - mean\n",
    "x_test = x_test - mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## expand the original image to 40x40, and use random crop 32x32\n",
    "\n",
    "def processing(image):\n",
    "    pic = np.zeros(shape = (40, 40, 3))\n",
    "    for c in range(image.shape[2]):\n",
    "        a = image[:, :, c]\n",
    "        a = np.pad(a, (4, 4))\n",
    "        pic[:, :, c] = a\n",
    "    pic = tf.image.random_crop(pic, [32, 32, 3], seed = 0)\n",
    "    return pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "            horizontal_flip=True,\n",
    "            preprocessing_function=processing,\n",
    "            validation_split=0.2)\n",
    "val_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "val_datagen.fit(x_val)\n",
    "test_datagen.fit(x_test)\n",
    "\n",
    "batch_size = 64\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(x_val, y_val, batch_size=batch_size)\n",
    "test_generator = test_datagen.flow(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build up Residual Attention-56 Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = Input(shape=(32, 32, 3))\n",
    "output = AttentionResNet56_spatial(img_input)\n",
    "model = Model(img_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 16)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 4)    68          activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 4)    16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 4)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 4)    148         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 4)    16          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 4)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   80          activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 16)   0           conv2d_3[0][0]                   \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 4)    68          activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 4)    16          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 4)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 4)    148         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 4)    16          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 4)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   80          activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 16)   0           conv2d_6[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 16)   64          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 16)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 4)    68          activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 4)    16          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 4)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 4)    148         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 4)    16          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 4)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 16)   80          activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 16)   0           conv2d_15[0][0]                  \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 16)     0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 16)     64          max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 16)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 4)      68          activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 4)      16          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 4)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 4)      148         activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 4)      16          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 4)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 16)     80          activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 16)     0           conv2d_21[0][0]                  \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 16)     0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 4, 4, 16)     64          max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 4, 4, 16)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 4, 4, 4)      68          activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 4, 4, 4)      16          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 4, 4, 4)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 4, 4, 4)      148         activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 4, 4, 4)      16          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 4, 4, 4)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 4, 4, 16)     80          activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 4, 16)     0           conv2d_27[0][0]                  \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 4, 4, 16)     64          add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 4, 4, 16)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 16)     64          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 4, 4, 4)      68          activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 16)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 4, 4, 4)      16          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 4)      68          activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 4, 4, 4)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 4)      16          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 4, 4, 4)      148         activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 8, 4)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 4, 4, 4)      16          conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 4)      148         activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 4, 4, 4)      0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 8, 4)      16          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 4, 4, 16)     80          activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 4)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 4, 4, 16)     0           conv2d_30[0][0]                  \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 16)     80          activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 8, 8, 16)     0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 16)     0           conv2d_24[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 16)     0           up_sampling2d[0][0]              \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 16)     64          add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 16)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 16)   64          add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 4)      68          activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 16)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 4)      16          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 4)    68          activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 4)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 4)    16          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 4)      148         activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 4)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 4)      16          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 4)    148         activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 4)      0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 4)    16          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 16)     80          activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 4)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 16)     0           conv2d_33[0][0]                  \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 16)   80          activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 16)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 16)   0           conv2d_18[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 16)   0           up_sampling2d_1[0][0]            \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 16)   64          add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 16)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 16)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 4)    68          activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 4)    68          activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 4)    16          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 4)    16          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 4)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 4)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 4)    148         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 4)    148         activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 4)    16          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 4)    16          conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 4)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 4)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   80          activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 16)   80          activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 16)   0           conv2d_9[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 16)   0           conv2d_36[0][0]                  \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 16)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 32, 16)   64          up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 4)    68          activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 16)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 4)    16          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 16)   272         activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 4)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 32, 32, 16)   64          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 4)    148         activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 32, 32, 16)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 4)    16          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 16)   272         activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 4)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 32, 32, 16)   2048        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 16)   80          activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 32, 32, 16)   0           layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 16)   0           conv2d_12[0][0]                  \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 32, 32, 16)   0           activation_39[0][0]              \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 32, 32, 16)   0           multiply[0][0]                   \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 32, 32, 16)   64          add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 32, 32, 16)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 4)    68          activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 32, 32, 4)    16          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 32, 32, 4)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 32, 32, 4)    148         activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 32, 32, 4)    16          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 32, 32, 4)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 32, 32, 16)   80          activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 32, 32, 16)   0           conv2d_41[0][0]                  \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 32, 32, 16)   64          add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 32, 32, 16)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 32, 8)    136         activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 32, 32, 8)    32          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 32, 32, 8)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 8)    584         activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 8)    32          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 32, 32, 16)   64          add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 8)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 32, 32, 16)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 32)   288         activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 32)   544         activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 16, 16, 32)   0           conv2d_45[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 32)   128         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 32)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 8)    264         activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 8)    32          conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 8)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 8)    584         activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 8)    32          conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 8)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 32)   288         activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 16, 16, 32)   0           conv2d_48[0][0]                  \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 32)     0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 32)     128         max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 32)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 8)      264         activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 8)      32          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 8)      0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 8)      584         activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 8)      32          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 8)      0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 32)     288         activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 8, 8, 32)     0           conv2d_57[0][0]                  \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 32)     0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 4, 4, 32)     128         max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 4, 4, 32)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 4, 4, 8)      264         activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 4, 4, 8)      32          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 4, 4, 8)      0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 4, 4, 8)      584         activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 4, 4, 8)      32          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 4, 4, 8)      0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 4, 4, 32)     288         activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 4, 4, 32)     0           conv2d_63[0][0]                  \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 4, 4, 32)     128         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 4, 4, 32)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 32)     128         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 4, 4, 8)      264         activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 32)     0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 4, 4, 8)      32          conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 8)      264         activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 4, 4, 8)      0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 8)      32          conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 4, 4, 8)      584         activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 8)      0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 4, 4, 8)      32          conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 8)      584         activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 4, 4, 8)      0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 8)      32          conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 4, 4, 32)     288         activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 8)      0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 4, 4, 32)     0           conv2d_66[0][0]                  \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 32)     288         activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 8, 8, 32)     0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 8, 8, 32)     0           conv2d_60[0][0]                  \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 8, 8, 32)     0           up_sampling2d_3[0][0]            \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 32)   128         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 32)     128         add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 32)     0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 8)    264         activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 8)      264         activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 8)    32          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 8)      32          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16, 16, 8)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 8)      0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 8)    584         activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 8)      584         activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 16, 16, 8)    32          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 8)      32          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 16, 16, 8)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 8)      0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 32)   288         activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 32)     288         activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 16, 16, 32)   0           conv2d_51[0][0]                  \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 8, 8, 32)     0           conv2d_69[0][0]                  \n",
      "                                                                 add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 16, 16, 32)   128         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 32)   0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 16, 16, 32)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 16, 16, 32)   128         up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 8)    264         activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 16, 16, 32)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 16, 16, 8)    32          conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 16, 16, 32)   1056        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 16, 16, 8)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 16, 16, 32)   128         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 8)    584         activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 16, 16, 32)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 16, 16, 8)    32          conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 16, 16, 32)   1056        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 8)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 16, 16, 32)   512         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 32)   288         activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 16, 16, 32)   0           layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 16, 16, 32)   0           conv2d_54[0][0]                  \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 16, 16, 32)   0           activation_73[0][0]              \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 16, 16, 32)   0           multiply_1[0][0]                 \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 16, 16, 32)   128         add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 16, 16, 32)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 16, 16, 8)    264         activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 16, 16, 8)    32          conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 16, 16, 8)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 16, 16, 8)    584         activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 16, 16, 8)    32          conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 16, 16, 8)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 16, 16, 32)   288         activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 16, 16, 32)   0           conv2d_74[0][0]                  \n",
      "                                                                 add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 16, 16, 32)   128         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 16, 16, 32)   0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 16, 16, 16)   528         activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 16, 16, 16)   64          conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 16, 16, 16)   0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 16)     2320        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 16)     64          conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 16, 16, 32)   128         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 16)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 16, 16, 32)   0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 64)     1088        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 64)     2112        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 8, 8, 64)     0           conv2d_78[0][0]                  \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 64)     256         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 64)     0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 16)     1040        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 16)     64          conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 16)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 16)     2320        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 16)     64          conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 16)     0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 64)     1088        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 8, 8, 64)     0           conv2d_81[0][0]                  \n",
      "                                                                 add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 4, 4, 64)     0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 4, 4, 64)     256         max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 4, 4, 64)     0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 4, 4, 16)     1040        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 4, 4, 16)     64          conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 4, 4, 16)     0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 4, 4, 16)     2320        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 4, 4, 16)     64          conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 4, 4, 16)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 4, 4, 64)     1088        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 4, 4, 64)     0           conv2d_90[0][0]                  \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 64)     256         add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 4, 4, 64)     256         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 64)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 4, 4, 64)     0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 16)     1040        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 4, 4, 16)     1040        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 16)     64          conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 4, 4, 16)     64          conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 16)     0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 4, 4, 16)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 16)     2320        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 4, 4, 16)     2320        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 16)     64          conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 4, 4, 16)     64          conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 16)     0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 4, 4, 16)     0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 64)     1088        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 4, 4, 64)     1088        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 8, 8, 64)     0           conv2d_84[0][0]                  \n",
      "                                                                 add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 4, 4, 64)     0           conv2d_93[0][0]                  \n",
      "                                                                 add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 64)     256         add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 8, 8, 64)     0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 64)     0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 64)     256         up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 16)     1040        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 8, 8, 64)     0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 16)     64          conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 64)     4160        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 16)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 8, 8, 64)     256         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 16)     2320        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 8, 8, 64)     0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 16)     64          conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 8, 8, 64)     4160        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 16)     0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 8, 8, 64)     128         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 64)     1088        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 8, 8, 64)     0           layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 8, 8, 64)     0           conv2d_87[0][0]                  \n",
      "                                                                 add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 8, 8, 64)     0           activation_98[0][0]              \n",
      "                                                                 add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 8, 8, 64)     0           multiply_2[0][0]                 \n",
      "                                                                 add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 8, 8, 64)     256         add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 8, 8, 64)     0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 8, 8, 16)     1040        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 8, 8, 16)     64          conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 8, 8, 16)     0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 8, 8, 16)     2320        activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 8, 8, 16)     64          conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 8, 8, 16)     0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 8, 8, 64)     1088        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 8, 8, 64)     0           conv2d_98[0][0]                  \n",
      "                                                                 add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 8, 8, 64)     256         add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 8, 8, 64)     0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 8, 8, 16)     1040        activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 8, 8, 16)     64          conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 8, 8, 16)     0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 8, 8, 16)     2320        activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 8, 8, 16)     64          conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 8, 8, 16)     0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 8, 8, 64)     1088        activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 8, 8, 64)     0           conv2d_101[0][0]                 \n",
      "                                                                 add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 8, 8, 64)     256         add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 8, 8, 64)     0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 8, 8, 16)     1040        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 8, 8, 16)     64          conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 8, 8, 16)     0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 8, 8, 16)     2320        activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 8, 8, 16)     64          conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 8, 8, 16)     0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 8, 8, 64)     1088        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 8, 8, 64)     0           conv2d_104[0][0]                 \n",
      "                                                                 add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 8, 8, 64)     256         add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 8, 8, 64)     0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 8, 8, 16)     1040        activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 8, 8, 16)     64          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 8, 8, 16)     0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 8, 8, 16)     2320        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 8, 8, 16)     64          conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 8, 8, 16)     0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 8, 8, 64)     1088        activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 8, 8, 64)     0           conv2d_107[0][0]                 \n",
      "                                                                 add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 8, 8, 64)     256         add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 8, 8, 64)     0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 64)           0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           650         flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 84,690\n",
      "Trainable params: 80,578\n",
      "Non-trainable params: 4,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build a learning rate call back\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    lr = 0.1\n",
    "    if epoch > 100:\n",
    "        lr *= 1e-1\n",
    "    elif epoch > 150:\n",
    "        lr *= 1e-2\n",
    "        \n",
    "    print('Learning rate:', lr)\n",
    "    return lr\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "## build an early stopping call back\n",
    "early_stopper = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.1\n"
     ]
    }
   ],
   "source": [
    "## use nesterov SGD as mentioned in the paper\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(lr_schedule(0), momentum=0.9, nesterov=True, name='SGD', decay = 0.0001),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.1\n",
      "Epoch 1/180\n",
      "625/625 [==============================] - 141s 226ms/step - loss: 1.5918 - accuracy: 0.4173 - val_loss: 2.0996 - val_accuracy: 0.3853 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 2/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 1.2872 - accuracy: 0.5382 - val_loss: 1.3748 - val_accuracy: 0.5315 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 3/180\n",
      "625/625 [==============================] - 137s 220ms/step - loss: 1.1487 - accuracy: 0.5925 - val_loss: 1.1122 - val_accuracy: 0.6124 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 4/180\n",
      "625/625 [==============================] - 137s 218ms/step - loss: 1.0459 - accuracy: 0.6322 - val_loss: 1.0180 - val_accuracy: 0.6436 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 5/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.9702 - accuracy: 0.6568 - val_loss: 0.9687 - val_accuracy: 0.6605 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 6/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.9150 - accuracy: 0.6788 - val_loss: 1.1211 - val_accuracy: 0.6210 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 7/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.8673 - accuracy: 0.6944 - val_loss: 1.0852 - val_accuracy: 0.6268 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 8/180\n",
      "625/625 [==============================] - 137s 220ms/step - loss: 0.8329 - accuracy: 0.7080 - val_loss: 0.9671 - val_accuracy: 0.6639 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 9/180\n",
      "625/625 [==============================] - 137s 220ms/step - loss: 0.8000 - accuracy: 0.7197 - val_loss: 0.8505 - val_accuracy: 0.7118 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 10/180\n",
      "625/625 [==============================] - 138s 220ms/step - loss: 0.7733 - accuracy: 0.7291 - val_loss: 0.9121 - val_accuracy: 0.6930 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 11/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.7438 - accuracy: 0.7430 - val_loss: 0.7832 - val_accuracy: 0.7271 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 12/180\n",
      "625/625 [==============================] - 138s 220ms/step - loss: 0.7253 - accuracy: 0.7463 - val_loss: 0.7452 - val_accuracy: 0.7419 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 13/180\n",
      "625/625 [==============================] - 138s 220ms/step - loss: 0.7054 - accuracy: 0.7516 - val_loss: 0.7495 - val_accuracy: 0.7368 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 14/180\n",
      "625/625 [==============================] - 136s 218ms/step - loss: 0.6857 - accuracy: 0.7599 - val_loss: 0.7551 - val_accuracy: 0.7385 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 15/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.6639 - accuracy: 0.7688 - val_loss: 0.7851 - val_accuracy: 0.7298 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 16/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.6520 - accuracy: 0.7733 - val_loss: 0.7484 - val_accuracy: 0.7426 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 17/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.6304 - accuracy: 0.7785 - val_loss: 0.7404 - val_accuracy: 0.7495 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 18/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.6152 - accuracy: 0.7852 - val_loss: 0.7297 - val_accuracy: 0.7500 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 19/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.5997 - accuracy: 0.7894 - val_loss: 0.8310 - val_accuracy: 0.7278 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 20/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.5931 - accuracy: 0.7932 - val_loss: 0.7427 - val_accuracy: 0.7522 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 21/180\n",
      "625/625 [==============================] - 136s 218ms/step - loss: 0.5810 - accuracy: 0.7958 - val_loss: 0.7097 - val_accuracy: 0.7639 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 22/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.5682 - accuracy: 0.8013 - val_loss: 0.7029 - val_accuracy: 0.7640 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 23/180\n",
      "625/625 [==============================] - 138s 220ms/step - loss: 0.5620 - accuracy: 0.8030 - val_loss: 0.6288 - val_accuracy: 0.7841 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 24/180\n",
      "625/625 [==============================] - 136s 218ms/step - loss: 0.5499 - accuracy: 0.8077 - val_loss: 0.6191 - val_accuracy: 0.7911 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 25/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.5414 - accuracy: 0.8106 - val_loss: 0.6442 - val_accuracy: 0.7850 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 26/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.5394 - accuracy: 0.8113 - val_loss: 0.6281 - val_accuracy: 0.7843 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 27/180\n",
      "625/625 [==============================] - 137s 220ms/step - loss: 0.5306 - accuracy: 0.8141 - val_loss: 0.6675 - val_accuracy: 0.7811 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 28/180\n",
      "625/625 [==============================] - 136s 218ms/step - loss: 0.5209 - accuracy: 0.8173 - val_loss: 0.6542 - val_accuracy: 0.7823 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 29/180\n",
      "625/625 [==============================] - 135s 215ms/step - loss: 0.5158 - accuracy: 0.8202 - val_loss: 0.6111 - val_accuracy: 0.7936 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 30/180\n",
      "625/625 [==============================] - 135s 217ms/step - loss: 0.5079 - accuracy: 0.8208 - val_loss: 0.8437 - val_accuracy: 0.7306 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 31/180\n",
      "625/625 [==============================] - 137s 218ms/step - loss: 0.5042 - accuracy: 0.8232 - val_loss: 0.5876 - val_accuracy: 0.8000 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 32/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.4956 - accuracy: 0.8270 - val_loss: 0.6777 - val_accuracy: 0.7789 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 33/180\n",
      "625/625 [==============================] - 137s 220ms/step - loss: 0.4786 - accuracy: 0.8332 - val_loss: 0.5720 - val_accuracy: 0.8085 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 34/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.4787 - accuracy: 0.8327 - val_loss: 0.5681 - val_accuracy: 0.8065 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 35/180\n",
      "625/625 [==============================] - 138s 220ms/step - loss: 0.4759 - accuracy: 0.8329 - val_loss: 0.5645 - val_accuracy: 0.8106 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 36/180\n",
      "625/625 [==============================] - 137s 220ms/step - loss: 0.4714 - accuracy: 0.8345 - val_loss: 0.5998 - val_accuracy: 0.8014 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 37/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.4660 - accuracy: 0.8385 - val_loss: 0.6051 - val_accuracy: 0.7955 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 38/180\n",
      "625/625 [==============================] - 137s 220ms/step - loss: 0.4625 - accuracy: 0.8385 - val_loss: 0.5783 - val_accuracy: 0.8013 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 39/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.4539 - accuracy: 0.8406 - val_loss: 0.5499 - val_accuracy: 0.8142 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 40/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.4480 - accuracy: 0.8425 - val_loss: 0.5920 - val_accuracy: 0.8034 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 41/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.4461 - accuracy: 0.8437 - val_loss: 0.5398 - val_accuracy: 0.8183 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 42/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.4456 - accuracy: 0.8440 - val_loss: 0.5682 - val_accuracy: 0.8126 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 43/180\n",
      "625/625 [==============================] - 136s 217ms/step - loss: 0.4428 - accuracy: 0.8453 - val_loss: 0.5757 - val_accuracy: 0.8086 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 44/180\n",
      "625/625 [==============================] - 134s 215ms/step - loss: 0.4314 - accuracy: 0.8468 - val_loss: 0.5990 - val_accuracy: 0.7998 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 45/180\n",
      "625/625 [==============================] - 136s 217ms/step - loss: 0.4284 - accuracy: 0.8492 - val_loss: 0.5254 - val_accuracy: 0.8229 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 46/180\n",
      "625/625 [==============================] - 140s 224ms/step - loss: 0.4256 - accuracy: 0.8501 - val_loss: 0.5477 - val_accuracy: 0.8170 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 47/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.4234 - accuracy: 0.8493 - val_loss: 0.5769 - val_accuracy: 0.8062 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 48/180\n",
      "625/625 [==============================] - 136s 217ms/step - loss: 0.4161 - accuracy: 0.8529 - val_loss: 0.5292 - val_accuracy: 0.8214 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 49/180\n",
      "625/625 [==============================] - 136s 217ms/step - loss: 0.4110 - accuracy: 0.8549 - val_loss: 0.5372 - val_accuracy: 0.8213 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 50/180\n",
      "625/625 [==============================] - 138s 220ms/step - loss: 0.4162 - accuracy: 0.8542 - val_loss: 0.5664 - val_accuracy: 0.8103 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 51/180\n",
      "625/625 [==============================] - 137s 220ms/step - loss: 0.4050 - accuracy: 0.8554 - val_loss: 0.5190 - val_accuracy: 0.8236 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 52/180\n",
      "625/625 [==============================] - 138s 220ms/step - loss: 0.4029 - accuracy: 0.8564 - val_loss: 0.5613 - val_accuracy: 0.8109 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 53/180\n",
      "625/625 [==============================] - 136s 217ms/step - loss: 0.3993 - accuracy: 0.8587 - val_loss: 0.5067 - val_accuracy: 0.8269 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 54/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.3971 - accuracy: 0.8595 - val_loss: 0.5226 - val_accuracy: 0.8234 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 55/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.3922 - accuracy: 0.8625 - val_loss: 0.5517 - val_accuracy: 0.8188 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 56/180\n",
      "625/625 [==============================] - 137s 220ms/step - loss: 0.3871 - accuracy: 0.8617 - val_loss: 0.5507 - val_accuracy: 0.8207 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 57/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.3848 - accuracy: 0.8644 - val_loss: 0.5352 - val_accuracy: 0.8218 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 58/180\n",
      "625/625 [==============================] - 138s 220ms/step - loss: 0.3813 - accuracy: 0.8650 - val_loss: 0.5200 - val_accuracy: 0.8254 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 59/180\n",
      "625/625 [==============================] - 136s 217ms/step - loss: 0.3806 - accuracy: 0.8655 - val_loss: 0.5121 - val_accuracy: 0.8270 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 60/180\n",
      "625/625 [==============================] - 136s 218ms/step - loss: 0.3762 - accuracy: 0.8654 - val_loss: 0.5490 - val_accuracy: 0.8171 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 61/180\n",
      "625/625 [==============================] - 136s 218ms/step - loss: 0.3759 - accuracy: 0.8672 - val_loss: 0.5363 - val_accuracy: 0.8204 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 62/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.3709 - accuracy: 0.8680 - val_loss: 0.5255 - val_accuracy: 0.8291 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 63/180\n",
      "625/625 [==============================] - 136s 217ms/step - loss: 0.3694 - accuracy: 0.8695 - val_loss: 0.5408 - val_accuracy: 0.8228 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 64/180\n",
      "625/625 [==============================] - 138s 220ms/step - loss: 0.3649 - accuracy: 0.8700 - val_loss: 0.5230 - val_accuracy: 0.8274 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 65/180\n",
      "625/625 [==============================] - 136s 218ms/step - loss: 0.3663 - accuracy: 0.8684 - val_loss: 0.5062 - val_accuracy: 0.8332 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 66/180\n",
      "625/625 [==============================] - 135s 217ms/step - loss: 0.3612 - accuracy: 0.8701 - val_loss: 0.5374 - val_accuracy: 0.8247 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 67/180\n",
      "625/625 [==============================] - 136s 217ms/step - loss: 0.3625 - accuracy: 0.8738 - val_loss: 0.5258 - val_accuracy: 0.8273 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 68/180\n",
      "625/625 [==============================] - 138s 220ms/step - loss: 0.3561 - accuracy: 0.8746 - val_loss: 0.5099 - val_accuracy: 0.8334 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 69/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.3562 - accuracy: 0.8740 - val_loss: 0.5251 - val_accuracy: 0.8275 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 70/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.3557 - accuracy: 0.8744 - val_loss: 0.5021 - val_accuracy: 0.8354 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 71/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.3542 - accuracy: 0.8745 - val_loss: 0.5128 - val_accuracy: 0.8310 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 72/180\n",
      "625/625 [==============================] - 134s 215ms/step - loss: 0.3505 - accuracy: 0.8756 - val_loss: 0.5411 - val_accuracy: 0.8194 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 73/180\n",
      "625/625 [==============================] - 137s 220ms/step - loss: 0.3477 - accuracy: 0.8769 - val_loss: 0.5156 - val_accuracy: 0.8338 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 74/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.3459 - accuracy: 0.8780 - val_loss: 0.5187 - val_accuracy: 0.8317 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 75/180\n",
      "625/625 [==============================] - 136s 218ms/step - loss: 0.3443 - accuracy: 0.8770 - val_loss: 0.5192 - val_accuracy: 0.8281 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 76/180\n",
      "625/625 [==============================] - 134s 215ms/step - loss: 0.3413 - accuracy: 0.8791 - val_loss: 0.5075 - val_accuracy: 0.8366 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 77/180\n",
      "625/625 [==============================] - 135s 217ms/step - loss: 0.3345 - accuracy: 0.8812 - val_loss: 0.5102 - val_accuracy: 0.8333 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 78/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.3343 - accuracy: 0.8804 - val_loss: 0.5243 - val_accuracy: 0.8303 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 79/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.3333 - accuracy: 0.8806 - val_loss: 0.4973 - val_accuracy: 0.8356 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 80/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.3352 - accuracy: 0.8806 - val_loss: 0.4829 - val_accuracy: 0.8370 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 81/180\n",
      "625/625 [==============================] - 136s 218ms/step - loss: 0.3350 - accuracy: 0.8789 - val_loss: 0.5148 - val_accuracy: 0.8328 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 82/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.3324 - accuracy: 0.8806 - val_loss: 0.5135 - val_accuracy: 0.8321 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 83/180\n",
      "625/625 [==============================] - 137s 220ms/step - loss: 0.3295 - accuracy: 0.8843 - val_loss: 0.5056 - val_accuracy: 0.8323 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 84/180\n",
      "625/625 [==============================] - 139s 223ms/step - loss: 0.3259 - accuracy: 0.8825 - val_loss: 0.5049 - val_accuracy: 0.8372 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 85/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.3247 - accuracy: 0.8838 - val_loss: 0.5073 - val_accuracy: 0.8362 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 86/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.3233 - accuracy: 0.8858 - val_loss: 0.4915 - val_accuracy: 0.8391 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 87/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.3233 - accuracy: 0.8836 - val_loss: 0.5111 - val_accuracy: 0.8338 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 88/180\n",
      "625/625 [==============================] - 136s 217ms/step - loss: 0.3199 - accuracy: 0.8863 - val_loss: 0.5190 - val_accuracy: 0.8333 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 89/180\n",
      "625/625 [==============================] - 138s 220ms/step - loss: 0.3229 - accuracy: 0.8853 - val_loss: 0.5001 - val_accuracy: 0.8368 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 90/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.3212 - accuracy: 0.8854 - val_loss: 0.5149 - val_accuracy: 0.8345 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 91/180\n",
      "625/625 [==============================] - 135s 217ms/step - loss: 0.3173 - accuracy: 0.8866 - val_loss: 0.4856 - val_accuracy: 0.8418 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 92/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.3119 - accuracy: 0.8892 - val_loss: 0.5504 - val_accuracy: 0.8245 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 93/180\n",
      "625/625 [==============================] - 139s 222ms/step - loss: 0.3101 - accuracy: 0.8896 - val_loss: 0.4869 - val_accuracy: 0.8418 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 94/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.3100 - accuracy: 0.8879 - val_loss: 0.5348 - val_accuracy: 0.8291 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 95/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.3103 - accuracy: 0.8884 - val_loss: 0.5169 - val_accuracy: 0.8313 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 96/180\n",
      "625/625 [==============================] - 137s 220ms/step - loss: 0.3097 - accuracy: 0.8906 - val_loss: 0.5021 - val_accuracy: 0.8386 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 97/180\n",
      "625/625 [==============================] - 138s 220ms/step - loss: 0.3019 - accuracy: 0.8929 - val_loss: 0.4861 - val_accuracy: 0.8438 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 98/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.3084 - accuracy: 0.8919 - val_loss: 0.5001 - val_accuracy: 0.8371 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 99/180\n",
      "625/625 [==============================] - 136s 217ms/step - loss: 0.2977 - accuracy: 0.8925 - val_loss: 0.4816 - val_accuracy: 0.8463 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 100/180\n",
      "625/625 [==============================] - 136s 218ms/step - loss: 0.3038 - accuracy: 0.8924 - val_loss: 0.5415 - val_accuracy: 0.8260 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 101/180\n",
      "625/625 [==============================] - 135s 215ms/step - loss: 0.3003 - accuracy: 0.8937 - val_loss: 0.5155 - val_accuracy: 0.8342 - lr: 0.1000\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 102/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.2802 - accuracy: 0.8994 - val_loss: 0.4588 - val_accuracy: 0.8493 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 103/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.2707 - accuracy: 0.9046 - val_loss: 0.4581 - val_accuracy: 0.8514 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 104/180\n",
      "625/625 [==============================] - 136s 217ms/step - loss: 0.2718 - accuracy: 0.9028 - val_loss: 0.4566 - val_accuracy: 0.8523 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 105/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.2632 - accuracy: 0.9039 - val_loss: 0.4555 - val_accuracy: 0.8522 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 106/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.2622 - accuracy: 0.9080 - val_loss: 0.4576 - val_accuracy: 0.8528 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 107/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.2608 - accuracy: 0.9075 - val_loss: 0.4570 - val_accuracy: 0.8520 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 108/180\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.2588 - accuracy: 0.9088 - val_loss: 0.4579 - val_accuracy: 0.8531 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 109/180\n",
      "625/625 [==============================] - 136s 217ms/step - loss: 0.2602 - accuracy: 0.9079 - val_loss: 0.4584 - val_accuracy: 0.8533 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 110/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.2616 - accuracy: 0.9074 - val_loss: 0.4582 - val_accuracy: 0.8506 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 111/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.2579 - accuracy: 0.9097 - val_loss: 0.4590 - val_accuracy: 0.8534 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 112/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.2570 - accuracy: 0.9094 - val_loss: 0.4598 - val_accuracy: 0.8515 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 113/180\n",
      "625/625 [==============================] - 137s 220ms/step - loss: 0.2571 - accuracy: 0.9099 - val_loss: 0.4605 - val_accuracy: 0.8533 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 114/180\n",
      "625/625 [==============================] - 136s 218ms/step - loss: 0.2588 - accuracy: 0.9091 - val_loss: 0.4587 - val_accuracy: 0.8549 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 115/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.2549 - accuracy: 0.9095 - val_loss: 0.4616 - val_accuracy: 0.8518 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 116/180\n",
      "625/625 [==============================] - 136s 217ms/step - loss: 0.2555 - accuracy: 0.9094 - val_loss: 0.4593 - val_accuracy: 0.8539 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 117/180\n",
      "625/625 [==============================] - 136s 218ms/step - loss: 0.2558 - accuracy: 0.9079 - val_loss: 0.4584 - val_accuracy: 0.8536 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 118/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.2518 - accuracy: 0.9110 - val_loss: 0.4605 - val_accuracy: 0.8524 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 119/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.2560 - accuracy: 0.9084 - val_loss: 0.4604 - val_accuracy: 0.8533 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 120/180\n",
      "625/625 [==============================] - 139s 223ms/step - loss: 0.2545 - accuracy: 0.9100 - val_loss: 0.4616 - val_accuracy: 0.8527 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 121/180\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.2492 - accuracy: 0.9104 - val_loss: 0.4603 - val_accuracy: 0.8524 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 122/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 0.2535 - accuracy: 0.9110 - val_loss: 0.4612 - val_accuracy: 0.8526 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 123/180\n",
      "625/625 [==============================] - 136s 217ms/step - loss: 0.2517 - accuracy: 0.9097 - val_loss: 0.4617 - val_accuracy: 0.8527 - lr: 0.0100\n",
      "Learning rate: 0.010000000000000002\n",
      "Epoch 124/180\n",
      "625/625 [==============================] - 140s 223ms/step - loss: 0.2536 - accuracy: 0.9104 - val_loss: 0.4631 - val_accuracy: 0.8520 - lr: 0.0100\n",
      "Epoch 00124: early stopping\n",
      "Time taken by above cell is 283.39295458396276 min.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs = 180, callbacks=[lr_callback, early_stopper]) # 256\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {} min.\".format((end-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, 124+1), history.history['loss'], label = 'training loss')\n",
    "plt.plot(range(1, 124+1), history.history['val_loss'], label = 'validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, 124+1), history.history['accuracy'], label = 'traning accuracy')\n",
    "plt.plot(range(1, 124+1), history.history['val_accuracy'], label = 'validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 3s 20ms/step - loss: 0.4909 - accuracy: 0.8464\n",
      "validation loss: 0.4631151258945465\n",
      "validation accuracy: 0.8519999980926514\n",
      "Test loss: 0.49094417691230774\n",
      "Test accuracy: 0.8464000225067139\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "val_scores = model.evaluate(val_generator, verbose=0)\n",
    "test_scores = model.evaluate(test_generator, verbose=1)\n",
    "print('validation loss:', val_scores[0])\n",
    "print('validation accuracy:', val_scores[1])\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the best model in a dictionary\n",
    "#save_dir = \"./save_models/\"\n",
    "#if not os.path.exists(save_dir):\n",
    "#    os.makedirs(save_dir)\n",
    "\n",
    "## Save your model\n",
    "#save_params = model.save_model()\n",
    "#with open(\"./save_models/best_model.pkl\", \"wb\") as output_file:\n",
    "#    pickle.dump(save_params, output_file)\n",
    "\n",
    "#model.save('ResidualAttention56_CIFAR10_model.h5')\n",
    "\n",
    "#history.model.save('./MODEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sava the weights\n",
    "model.save_weights('ResidualAttention56_spatial_CIFAR10_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
