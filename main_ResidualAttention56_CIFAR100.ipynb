{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Attention-56 Model(mixed attention) using CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, TensorBoard\n",
    "#from utils.preprocess import CIFAR_preprocess, add_noise\n",
    "from utils.AttentionResNet_CIFAR100 import AttentionResNet56\n",
    "from utils.residual_unit_CIFAR import residual_unit\n",
    "from utils.attention_block import attention_stage_1, attention_stage_2, attention_stage_3\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR-100 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (40000, 32, 32, 3)\n",
      "y_train shape: (40000,)\n",
      "x_validation shape: (10000, 32, 32, 3)\n",
      "y_validation shape: (10000,)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "## dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "train_num = int(len(x_train) * 0.8)\n",
    "x_val = x_train[train_num:, :, :, :]\n",
    "y_val = y_train[train_num:]\n",
    "y_val = y_val.reshape(-1)\n",
    "x_train = x_train[:train_num, :, :, :]\n",
    "y_train = y_train[:train_num]\n",
    "y_train = y_train.reshape(-1)\n",
    "\n",
    "y_test = y_test.reshape(-1)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_validation shape:', x_val.shape)\n",
    "print('y_validation shape:', y_val.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean for each channel\n",
    "mean = np.array(np.mean(x_train, axis=(0, 1, 2))).reshape([1,1,1,3])\n",
    "x_train = x_train-mean\n",
    "x_val = x_val - mean\n",
    "x_test = x_test - mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## expand the original image to 40x40, and use random crop 32x32\n",
    "\n",
    "def processing(image):\n",
    "    pic = np.zeros(shape = (40, 40, 3))\n",
    "    for c in range(image.shape[2]):\n",
    "        a = image[:, :, c]\n",
    "        a = np.pad(a, (4, 4))\n",
    "        pic[:, :, c] = a\n",
    "    pic = tf.image.random_crop(pic, [32, 32, 3], seed = 0)\n",
    "    return pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "            horizontal_flip=True,\n",
    "            preprocessing_function=processing,\n",
    "            validation_split=0.2)\n",
    "val_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "val_datagen.fit(x_val)\n",
    "test_datagen.fit(x_test)\n",
    "\n",
    "batch_size = 64\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(x_val, y_val, batch_size=batch_size)\n",
    "test_generator = test_datagen.flow(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build up Residual Attention-56 Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = Input(shape=(32, 32, 3))\n",
    "output = AttentionResNet56(img_input)\n",
    "model = Model(img_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 16)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 4)    68          activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 4)    16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 4)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 4)    148         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 4)    16          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 4)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   80          activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 16)   0           conv2d_3[0][0]                   \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 4)    68          activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 4)    16          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 4)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 4)    148         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 4)    16          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 4)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   80          activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 16)   0           conv2d_6[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 16)   64          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 16)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 4)    68          activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 4)    16          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 4)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 4)    148         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 4)    16          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 4)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 16)   80          activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 16)   0           conv2d_15[0][0]                  \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 16)     0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 16)     64          max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 16)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 4)      68          activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 4)      16          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 4)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 4)      148         activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 4)      16          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 4)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 16)     80          activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 16)     0           conv2d_21[0][0]                  \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 16)     0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 4, 4, 16)     64          max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 4, 4, 16)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 4, 4, 4)      68          activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 4, 4, 4)      16          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 4, 4, 4)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 4, 4, 4)      148         activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 4, 4, 4)      16          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 4, 4, 4)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 4, 4, 16)     80          activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 4, 16)     0           conv2d_27[0][0]                  \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 4, 4, 16)     64          add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 4, 4, 16)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 16)     64          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 4, 4, 4)      68          activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 16)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 4, 4, 4)      16          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 4)      68          activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 4, 4, 4)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 4)      16          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 4, 4, 4)      148         activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 8, 4)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 4, 4, 4)      16          conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 4)      148         activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 4, 4, 4)      0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 8, 4)      16          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 4, 4, 16)     80          activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 4)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 4, 4, 16)     0           conv2d_30[0][0]                  \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 16)     80          activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 8, 8, 16)     0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 16)     0           conv2d_24[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 16)     0           up_sampling2d[0][0]              \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 16)     64          add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 16)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 16)   64          add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 4)      68          activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 16)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 4)      16          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 4)    68          activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 4)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 4)    16          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 4)      148         activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 4)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 4)      16          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 4)    148         activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 4)      0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 4)    16          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 16)     80          activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 4)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 16)     0           conv2d_33[0][0]                  \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 16)   80          activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 16)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 16)   0           conv2d_18[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 16)   0           up_sampling2d_1[0][0]            \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 16)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 16)   64          add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 4)    68          activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 16)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 4)    16          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 4)    68          activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 4)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 4)    16          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 4)    148         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 4)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 4)    16          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 4)    148         activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 4)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 4)    16          conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   80          activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 4)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 16)   0           conv2d_9[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 16)   80          activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 16)   0           conv2d_36[0][0]                  \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 16)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 4)    68          activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 32, 16)   64          up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 4)    16          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 16)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 4)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 16)   272         activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 4)    148         activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 32, 32, 16)   64          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 4)    16          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 32, 32, 16)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 4)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 16)   272         activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 16)   80          activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 32, 32, 16)   0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 16)   0           conv2d_12[0][0]                  \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 32, 32, 16)   0           activation_39[0][0]              \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 32, 32, 16)   0           multiply[0][0]                   \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 32, 32, 16)   64          add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 32, 32, 16)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 4)    68          activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 32, 32, 4)    16          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 32, 32, 4)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 32, 32, 4)    148         activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 32, 32, 4)    16          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 32, 32, 4)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 32, 32, 16)   80          activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 32, 32, 16)   0           conv2d_41[0][0]                  \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 32, 32, 16)   64          add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 32, 32, 16)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 32, 8)    136         activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 32, 32, 8)    32          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 32, 32, 8)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 8)    584         activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 8)    32          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 32, 32, 16)   64          add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 8)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 32, 32, 16)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 32)   288         activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 32)   544         activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 16, 16, 32)   0           conv2d_45[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 32)   128         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 32)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 8)    264         activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 8)    32          conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 8)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 8)    584         activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 8)    32          conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 8)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 32)   288         activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 16, 16, 32)   0           conv2d_48[0][0]                  \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 32)     0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 32)     128         max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 32)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 8)      264         activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 8)      32          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 8)      0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 8)      584         activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 8)      32          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 8)      0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 32)     288         activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 8, 8, 32)     0           conv2d_57[0][0]                  \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 32)     0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 4, 4, 32)     128         max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 4, 4, 32)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 4, 4, 8)      264         activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 4, 4, 8)      32          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 4, 4, 8)      0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 4, 4, 8)      584         activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 4, 4, 8)      32          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 4, 4, 8)      0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 4, 4, 32)     288         activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 4, 4, 32)     0           conv2d_63[0][0]                  \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 4, 4, 32)     128         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 4, 4, 32)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 32)     128         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 4, 4, 8)      264         activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 32)     0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 4, 4, 8)      32          conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 8)      264         activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 4, 4, 8)      0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 8)      32          conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 4, 4, 8)      584         activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 8)      0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 4, 4, 8)      32          conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 8)      584         activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 4, 4, 8)      0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 8)      32          conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 4, 4, 32)     288         activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 8)      0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 4, 4, 32)     0           conv2d_66[0][0]                  \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 32)     288         activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 8, 8, 32)     0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 8, 8, 32)     0           conv2d_60[0][0]                  \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 32)   128         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 8, 8, 32)     0           up_sampling2d_3[0][0]            \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 32)     128         add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 8)    264         activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 32)     0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 8)    32          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 8)      264         activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16, 16, 8)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 8)      32          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 8)    584         activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 8)      0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 16, 16, 8)    32          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 8)      584         activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 16, 16, 8)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 8)      32          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 32)   288         activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 8)      0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 16, 16, 32)   0           conv2d_51[0][0]                  \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 32)     288         activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 16, 16, 32)   128         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 8, 8, 32)     0           conv2d_69[0][0]                  \n",
      "                                                                 add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 16, 16, 32)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 32)   0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 8)    264         activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 16, 16, 32)   128         up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 16, 16, 8)    32          conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 16, 16, 32)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 16, 16, 8)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 16, 16, 32)   1056        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 8)    584         activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 16, 16, 32)   128         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 16, 16, 8)    32          conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 16, 16, 32)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 8)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 16, 16, 32)   1056        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 32)   288         activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 16, 16, 32)   0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 16, 16, 32)   0           conv2d_54[0][0]                  \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 16, 16, 32)   0           activation_73[0][0]              \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 16, 16, 32)   0           multiply_1[0][0]                 \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 16, 16, 32)   128         add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 16, 16, 32)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 16, 16, 8)    264         activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 16, 16, 8)    32          conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 16, 16, 8)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 16, 16, 8)    584         activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 16, 16, 8)    32          conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 16, 16, 8)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 16, 16, 32)   288         activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 16, 16, 32)   0           conv2d_74[0][0]                  \n",
      "                                                                 add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 16, 16, 32)   128         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 16, 16, 32)   0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 16, 16, 16)   528         activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 16, 16, 16)   64          conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 16, 16, 16)   0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 16)     2320        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 16)     64          conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 16, 16, 32)   128         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 16)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 16, 16, 32)   0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 64)     1088        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 64)     2112        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 8, 8, 64)     0           conv2d_78[0][0]                  \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 64)     256         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 64)     0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 16)     1040        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 16)     64          conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 16)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 16)     2320        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 16)     64          conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 16)     0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 64)     1088        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 8, 8, 64)     0           conv2d_81[0][0]                  \n",
      "                                                                 add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 4, 4, 64)     0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 4, 4, 64)     256         max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 4, 4, 64)     0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 4, 4, 16)     1040        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 4, 4, 16)     64          conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 4, 4, 16)     0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 4, 4, 16)     2320        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 4, 4, 16)     64          conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 4, 4, 16)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 4, 4, 64)     1088        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 64)     256         add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 4, 4, 64)     0           conv2d_90[0][0]                  \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 64)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 4, 4, 64)     256         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 16)     1040        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 4, 4, 64)     0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 16)     64          conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 4, 4, 16)     1040        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 16)     0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 4, 4, 16)     64          conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 16)     2320        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 4, 4, 16)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 16)     64          conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 4, 4, 16)     2320        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 16)     0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 4, 4, 16)     64          conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 64)     1088        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 4, 4, 16)     0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 8, 8, 64)     0           conv2d_84[0][0]                  \n",
      "                                                                 add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 4, 4, 64)     1088        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 64)     256         add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 4, 4, 64)     0           conv2d_93[0][0]                  \n",
      "                                                                 add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 64)     0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 8, 8, 64)     0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 16)     1040        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 64)     256         up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 16)     64          conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 8, 8, 64)     0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 16)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 64)     4160        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 16)     2320        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 8, 8, 64)     256         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 16)     64          conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 8, 8, 64)     0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 16)     0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 8, 8, 64)     4160        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 64)     1088        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 8, 8, 64)     0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 8, 8, 64)     0           conv2d_87[0][0]                  \n",
      "                                                                 add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 8, 8, 64)     0           activation_98[0][0]              \n",
      "                                                                 add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 8, 8, 64)     0           multiply_2[0][0]                 \n",
      "                                                                 add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 8, 8, 64)     256         add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 8, 8, 64)     0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 8, 8, 16)     1040        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 8, 8, 16)     64          conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 8, 8, 16)     0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 8, 8, 16)     2320        activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 8, 8, 16)     64          conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 8, 8, 16)     0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 8, 8, 64)     1088        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 8, 8, 64)     0           conv2d_98[0][0]                  \n",
      "                                                                 add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 8, 8, 64)     256         add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 8, 8, 64)     0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 8, 8, 16)     1040        activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 8, 8, 16)     64          conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 8, 8, 16)     0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 8, 8, 16)     2320        activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 8, 8, 16)     64          conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 8, 8, 16)     0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 8, 8, 64)     1088        activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 8, 8, 64)     0           conv2d_101[0][0]                 \n",
      "                                                                 add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 8, 8, 64)     256         add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 8, 8, 64)     0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 8, 8, 16)     1040        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 8, 8, 16)     64          conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 8, 8, 16)     0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 8, 8, 16)     2320        activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 8, 8, 16)     64          conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 8, 8, 16)     0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 8, 8, 64)     1088        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 8, 8, 64)     0           conv2d_104[0][0]                 \n",
      "                                                                 add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 8, 8, 64)     256         add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 8, 8, 64)     0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 8, 8, 16)     1040        activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 8, 8, 16)     64          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 8, 8, 16)     0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 8, 8, 16)     2320        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 8, 8, 16)     64          conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 8, 8, 16)     0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 8, 8, 64)     1088        activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 8, 8, 64)     0           conv2d_107[0][0]                 \n",
      "                                                                 add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 8, 8, 64)     256         add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 8, 8, 64)     0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 64)           0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          6500        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 87,852\n",
      "Trainable params: 83,740\n",
      "Non-trainable params: 4,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build a learning rate call back\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    lr = 0.1\n",
    "    if epoch > 100:\n",
    "        lr *= 1e-1\n",
    "    elif epoch > 150:\n",
    "        lr *= 1e-2\n",
    "        \n",
    "    print('Learning rate:', lr)\n",
    "    return lr\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "## build an early stopping call back\n",
    "early_stopper = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.1\n"
     ]
    }
   ],
   "source": [
    "## use nesterov SGD as mentioned in the paper\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(lr_schedule(0), momentum=0.9, nesterov=True, name='SGD', decay = 0.0001),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.1\n",
      "Epoch 1/180\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 4.0042 - accuracy: 0.0794 - val_loss: 4.5879 - val_accuracy: 0.0840 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 2/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 3.5081 - accuracy: 0.1544 - val_loss: 3.4184 - val_accuracy: 0.1874 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 3/180\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 3.1627 - accuracy: 0.2156 - val_loss: 3.2890 - val_accuracy: 0.2146 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 4/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 2.9068 - accuracy: 0.2658 - val_loss: 3.1423 - val_accuracy: 0.2410 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 5/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 2.7319 - accuracy: 0.3010 - val_loss: 2.8501 - val_accuracy: 0.2907 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 6/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 2.6028 - accuracy: 0.3233 - val_loss: 2.7600 - val_accuracy: 0.3087 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 7/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 2.4883 - accuracy: 0.3489 - val_loss: 2.6935 - val_accuracy: 0.3236 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 8/180\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 2.3874 - accuracy: 0.3724 - val_loss: 2.6308 - val_accuracy: 0.3352 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 9/180\n",
      "625/625 [==============================] - 131s 209ms/step - loss: 2.3054 - accuracy: 0.3902 - val_loss: 2.6259 - val_accuracy: 0.3440 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 10/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 2.2362 - accuracy: 0.4034 - val_loss: 2.5626 - val_accuracy: 0.3643 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 11/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 2.1788 - accuracy: 0.4164 - val_loss: 2.2941 - val_accuracy: 0.4051 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 12/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 2.1176 - accuracy: 0.4291 - val_loss: 2.2983 - val_accuracy: 0.4045 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 13/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 2.0700 - accuracy: 0.4430 - val_loss: 2.4145 - val_accuracy: 0.3872 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 14/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 2.0314 - accuracy: 0.4500 - val_loss: 2.2620 - val_accuracy: 0.4096 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 15/180\n",
      "625/625 [==============================] - 132s 212ms/step - loss: 1.9839 - accuracy: 0.4597 - val_loss: 2.5118 - val_accuracy: 0.3742 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 16/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.9417 - accuracy: 0.4720 - val_loss: 2.4059 - val_accuracy: 0.4053 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 17/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.9169 - accuracy: 0.4760 - val_loss: 2.1916 - val_accuracy: 0.4364 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 18/180\n",
      "625/625 [==============================] - 132s 210ms/step - loss: 1.8717 - accuracy: 0.4878 - val_loss: 2.1546 - val_accuracy: 0.4378 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 19/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.8561 - accuracy: 0.4895 - val_loss: 2.1221 - val_accuracy: 0.4464 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 20/180\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 1.8205 - accuracy: 0.4976 - val_loss: 2.2366 - val_accuracy: 0.4267 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 21/180\n",
      "625/625 [==============================] - 131s 209ms/step - loss: 1.7926 - accuracy: 0.5052 - val_loss: 2.2809 - val_accuracy: 0.4337 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 22/180\n",
      "625/625 [==============================] - 132s 210ms/step - loss: 1.7728 - accuracy: 0.5092 - val_loss: 2.0531 - val_accuracy: 0.4604 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 23/180\n",
      "625/625 [==============================] - 131s 209ms/step - loss: 1.7504 - accuracy: 0.5156 - val_loss: 2.0445 - val_accuracy: 0.4698 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 24/180\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 1.7354 - accuracy: 0.5162 - val_loss: 2.0865 - val_accuracy: 0.4604 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 25/180\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 1.7083 - accuracy: 0.5253 - val_loss: 2.1522 - val_accuracy: 0.4532 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 26/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.6968 - accuracy: 0.5253 - val_loss: 2.0089 - val_accuracy: 0.4855 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 27/180\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 1.6784 - accuracy: 0.5329 - val_loss: 2.1459 - val_accuracy: 0.4575 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 28/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.6598 - accuracy: 0.5370 - val_loss: 2.0403 - val_accuracy: 0.4794 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 29/180\n",
      "625/625 [==============================] - 131s 209ms/step - loss: 1.6446 - accuracy: 0.5437 - val_loss: 2.4423 - val_accuracy: 0.4175 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 30/180\n",
      "625/625 [==============================] - 130s 207ms/step - loss: 1.6263 - accuracy: 0.5452 - val_loss: 2.0888 - val_accuracy: 0.4688 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 31/180\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 1.6071 - accuracy: 0.5501 - val_loss: 2.1670 - val_accuracy: 0.4645 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 32/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.5932 - accuracy: 0.5518 - val_loss: 2.0637 - val_accuracy: 0.4714 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 33/180\n",
      "625/625 [==============================] - 130s 208ms/step - loss: 1.5827 - accuracy: 0.5538 - val_loss: 2.0360 - val_accuracy: 0.4778 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 34/180\n",
      "625/625 [==============================] - 131s 209ms/step - loss: 1.5721 - accuracy: 0.5572 - val_loss: 2.0267 - val_accuracy: 0.4858 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 35/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.5561 - accuracy: 0.5630 - val_loss: 1.9789 - val_accuracy: 0.4889 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 36/180\n",
      "625/625 [==============================] - 130s 208ms/step - loss: 1.5416 - accuracy: 0.5648 - val_loss: 2.0468 - val_accuracy: 0.4852 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 37/180\n",
      "625/625 [==============================] - 131s 209ms/step - loss: 1.5332 - accuracy: 0.5683 - val_loss: 2.0089 - val_accuracy: 0.4875 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 38/180\n",
      "625/625 [==============================] - 130s 208ms/step - loss: 1.5207 - accuracy: 0.5712 - val_loss: 2.0845 - val_accuracy: 0.4756 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 39/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.5090 - accuracy: 0.5727 - val_loss: 1.9376 - val_accuracy: 0.4999 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 40/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.5022 - accuracy: 0.5748 - val_loss: 1.9561 - val_accuracy: 0.5001 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 41/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.4892 - accuracy: 0.5800 - val_loss: 1.9577 - val_accuracy: 0.4921 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 42/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.4861 - accuracy: 0.5805 - val_loss: 1.9534 - val_accuracy: 0.5030 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 43/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.4701 - accuracy: 0.5835 - val_loss: 1.9323 - val_accuracy: 0.5033 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 44/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.4638 - accuracy: 0.5839 - val_loss: 1.9716 - val_accuracy: 0.4999 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 45/180\n",
      "625/625 [==============================] - 131s 209ms/step - loss: 1.4617 - accuracy: 0.5852 - val_loss: 2.1034 - val_accuracy: 0.4835 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 46/180\n",
      "625/625 [==============================] - 132s 210ms/step - loss: 1.4404 - accuracy: 0.5931 - val_loss: 1.8858 - val_accuracy: 0.5062 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 47/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.4422 - accuracy: 0.5885 - val_loss: 1.9544 - val_accuracy: 0.4986 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 48/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.4203 - accuracy: 0.5943 - val_loss: 1.9277 - val_accuracy: 0.5024 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 49/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.4201 - accuracy: 0.5971 - val_loss: 1.9072 - val_accuracy: 0.5086 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 50/180\n",
      "625/625 [==============================] - 131s 209ms/step - loss: 1.4081 - accuracy: 0.5992 - val_loss: 1.8959 - val_accuracy: 0.5188 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 51/180\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 1.4058 - accuracy: 0.5986 - val_loss: 1.8907 - val_accuracy: 0.5156 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 52/180\n",
      "625/625 [==============================] - 132s 210ms/step - loss: 1.4019 - accuracy: 0.5981 - val_loss: 1.9055 - val_accuracy: 0.5143 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 53/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.3840 - accuracy: 0.6055 - val_loss: 1.9620 - val_accuracy: 0.5064 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 54/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.3904 - accuracy: 0.6020 - val_loss: 1.9059 - val_accuracy: 0.5130 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 55/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.3698 - accuracy: 0.6093 - val_loss: 1.9525 - val_accuracy: 0.5094 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 56/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.3677 - accuracy: 0.6061 - val_loss: 2.0155 - val_accuracy: 0.4994 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 57/180\n",
      "625/625 [==============================] - 131s 209ms/step - loss: 1.3635 - accuracy: 0.6112 - val_loss: 1.8751 - val_accuracy: 0.5216 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 58/180\n",
      "625/625 [==============================] - 132s 210ms/step - loss: 1.3574 - accuracy: 0.6097 - val_loss: 1.8767 - val_accuracy: 0.5167 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 59/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.3613 - accuracy: 0.6113 - val_loss: 1.8742 - val_accuracy: 0.5237 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 60/180\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 1.3445 - accuracy: 0.6152 - val_loss: 1.8764 - val_accuracy: 0.5261 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 61/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.3401 - accuracy: 0.6155 - val_loss: 1.8687 - val_accuracy: 0.5269 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 62/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.3379 - accuracy: 0.6167 - val_loss: 1.8560 - val_accuracy: 0.5186 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 63/180\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 1.3338 - accuracy: 0.6168 - val_loss: 1.9686 - val_accuracy: 0.5070 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 64/180\n",
      "625/625 [==============================] - 131s 209ms/step - loss: 1.3168 - accuracy: 0.6211 - val_loss: 1.9105 - val_accuracy: 0.5161 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 65/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.3118 - accuracy: 0.6237 - val_loss: 1.9332 - val_accuracy: 0.5195 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 66/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.3016 - accuracy: 0.6230 - val_loss: 1.9735 - val_accuracy: 0.5036 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 67/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.3092 - accuracy: 0.6214 - val_loss: 1.8963 - val_accuracy: 0.5239 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 68/180\n",
      "625/625 [==============================] - 131s 209ms/step - loss: 1.2984 - accuracy: 0.6272 - val_loss: 1.9056 - val_accuracy: 0.5191 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 69/180\n",
      "625/625 [==============================] - 131s 209ms/step - loss: 1.2969 - accuracy: 0.6242 - val_loss: 1.8560 - val_accuracy: 0.5320 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 70/180\n",
      "625/625 [==============================] - 132s 210ms/step - loss: 1.2882 - accuracy: 0.6281 - val_loss: 1.9334 - val_accuracy: 0.5195 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 71/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.2856 - accuracy: 0.6267 - val_loss: 1.8588 - val_accuracy: 0.5250 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 72/180\n",
      "625/625 [==============================] - 141s 225ms/step - loss: 1.2770 - accuracy: 0.6296 - val_loss: 2.0529 - val_accuracy: 0.5042 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 73/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.2761 - accuracy: 0.6291 - val_loss: 1.8404 - val_accuracy: 0.5346 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 74/180\n",
      "625/625 [==============================] - 132s 210ms/step - loss: 1.2690 - accuracy: 0.6333 - val_loss: 1.8294 - val_accuracy: 0.5355 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 75/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.2622 - accuracy: 0.6330 - val_loss: 1.8440 - val_accuracy: 0.5326 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 76/180\n",
      "625/625 [==============================] - 131s 209ms/step - loss: 1.2643 - accuracy: 0.6337 - val_loss: 1.8985 - val_accuracy: 0.5276 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 77/180\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 1.2571 - accuracy: 0.6355 - val_loss: 2.0100 - val_accuracy: 0.5114 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 78/180\n",
      "625/625 [==============================] - 131s 209ms/step - loss: 1.2538 - accuracy: 0.6340 - val_loss: 1.8767 - val_accuracy: 0.5310 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 79/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.2559 - accuracy: 0.6350 - val_loss: 1.9484 - val_accuracy: 0.5138 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 80/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.2461 - accuracy: 0.6379 - val_loss: 1.8496 - val_accuracy: 0.5359 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 81/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.2329 - accuracy: 0.6414 - val_loss: 1.9099 - val_accuracy: 0.5229 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 82/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.2330 - accuracy: 0.6413 - val_loss: 1.8565 - val_accuracy: 0.5355 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 83/180\n",
      "625/625 [==============================] - 130s 209ms/step - loss: 1.2385 - accuracy: 0.6385 - val_loss: 1.9261 - val_accuracy: 0.5233 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 84/180\n",
      "625/625 [==============================] - 130s 209ms/step - loss: 1.2232 - accuracy: 0.6431 - val_loss: 1.9399 - val_accuracy: 0.5217 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 86/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.2287 - accuracy: 0.6408 - val_loss: 1.9524 - val_accuracy: 0.5158 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 87/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.2216 - accuracy: 0.6438 - val_loss: 1.9357 - val_accuracy: 0.5248 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 88/180\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 1.2160 - accuracy: 0.6446 - val_loss: 1.9292 - val_accuracy: 0.5277 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 89/180\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 1.2099 - accuracy: 0.6453 - val_loss: 2.0525 - val_accuracy: 0.5161 - lr: 0.1000\n",
      "Learning rate: 0.1\n",
      "Epoch 90/180\n",
      "625/625 [==============================] - 131s 209ms/step - loss: 1.2062 - accuracy: 0.6464 - val_loss: 1.9007 - val_accuracy: 0.5308 - lr: 0.1000\n",
      "Epoch 00090: early stopping\n",
      "Time taken by above cell is 198.0048654874166 min.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs = 180, callbacks=[lr_callback, early_stopper]) # 256\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {} min.\".format((end-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, 90+1), history.history['loss'], label = 'training loss')\n",
    "plt.plot(range(1, 90+1), history.history['val_loss'], label = 'validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, 90+1), history.history['accuracy'], label = 'traning accuracy')\n",
    "plt.plot(range(1, 90+1), history.history['val_accuracy'], label = 'validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 3s 19ms/step - loss: 1.8933 - accuracy: 0.5298\n",
      "validation loss: 1.9007320404052734\n",
      "validation accuracy: 0.5307999849319458\n",
      "Test loss: 1.893290638923645\n",
      "Test accuracy: 0.5297999978065491\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "val_scores = model.evaluate(val_generator, verbose=0)\n",
    "test_scores = model.evaluate(test_generator, verbose=1)\n",
    "print('validation loss:', val_scores[0])\n",
    "print('validation accuracy:', val_scores[1])\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the best model in a dictionary\n",
    "#save_dir = \"./save_models/\"\n",
    "#if not os.path.exists(save_dir):\n",
    "#    os.makedirs(save_dir)\n",
    "\n",
    "## Save your model\n",
    "#save_params = model.save_model()\n",
    "#with open(\"./save_models/best_model.pkl\", \"wb\") as output_file:\n",
    "#    pickle.dump(save_params, output_file)\n",
    "\n",
    "#model.save('ResidualAttention56_CIFAR10_model.h5')\n",
    "\n",
    "#history.model.save('./MODEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sava the weights\n",
    "model.save_weights('ResidualAttention56_CIFAR100_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
